{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff086b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load csv file with semicolon separator\n",
    "df = pd.read_csv(\"TrafficAttackFDI.csv\", sep=\";\")\n",
    "\n",
    "# replace all instances of semicolon with comma\n",
    "df.replace(\";\", \",\", inplace=True)\n",
    "\n",
    "# save the new csv file with comma separator\n",
    "df.to_csv(\"goose_data_new-2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d547977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      "1    6728\n",
      "0    4395\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Count the number of instances in each class\n",
    "class_counts = goose_df['label'].value_counts()\n",
    "\n",
    "# Print the class counts\n",
    "print(\"Class counts:\")\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31be2f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.2011721134185791 seconds\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       835\n",
      "           1       1.00      1.00      1.00      1390\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RFC without any sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification report:\\n\", cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a1e0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.20358967781066895 seconds\n",
      "\n",
      "Classification report for Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       893\n",
      "           1       1.00      1.00      1.00      1332\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RFC using feature engineering and balancing using undersampling/oversampling\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using RandomOverSampler\n",
    "#ros = RandomOverSampler()\n",
    "#X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Balance the dataset using undersampling with the RandomUnderSampler\n",
    "#rus = RandomUnderSampler()\n",
    "#X, y = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the Random Forest Classifier model\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set using Random Forest Classifier\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for Random Forest Classifier\n",
    "cr_rfc = classification_report(y_test, y_pred_rfc)\n",
    "print(\"\\nClassification report for Random Forest Classifier:\\n\", cr_rfc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17bc5a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.049379825592041016 seconds\n",
      "\n",
      "Classification report for Gaussian Mixture Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     882.0\n",
      "           1       0.00      0.00      0.00     876.0\n",
      "\n",
      "    accuracy                           0.00    1758.0\n",
      "   macro avg       0.00      0.00      0.00    1758.0\n",
      "weighted avg       0.00      0.00      0.00    1758.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gaussian Mixture Model using feature engineering and balancing using undersampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using RandomOverSampler\n",
    "#ros = RandomOverSampler()\n",
    "#X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Balance the dataset using undersampling with the RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X, y = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=2)\n",
    "gmm.fit(X_train)\n",
    "\n",
    "# Predict the test set using Gaussian Mixture Model\n",
    "y_pred_gmm = gmm.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for Gaussian Mixture Model\n",
    "cr_gmm = classification_report(y_test, y_pred_gmm)\n",
    "print(\"\\nClassification report for Gaussian Mixture Model:\\n\", cr_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d49a131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.03442049026489258 seconds\n",
      "\n",
      "Classification report for Support Vector Machine (SVM):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       872\n",
      "           1       1.00      1.00      1.00      1353\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM using scikit-learn's SVC without sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "#Train the Support Vector Machine (SVM) model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "#Predict the test set using SVM\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "#Calculate the precision, recall, and f1-score for SVM\n",
    "cr_svm = classification_report(y_test, y_pred_svm, zero_division=1)\n",
    "print(\"\\nClassification report for Support Vector Machine (SVM):\\n\", cr_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40e7e4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.040938377380371094 seconds\n",
      "\n",
      "Classification report for Support Vector Machine (SVM):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1364\n",
      "           1       1.00      1.00      1.00      1328\n",
      "\n",
      "    accuracy                           1.00      2692\n",
      "   macro avg       1.00      1.00      1.00      2692\n",
      "weighted avg       1.00      1.00      1.00      2692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM using scikit-learn's SVC with over sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Balance the dataset using undersampling with the RandomUnderSampler\n",
    "#rus = RandomUnderSampler()\n",
    "#X, y = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "#Train the Support Vector Machine (SVM) model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "#Predict the test set using SVM\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "#Calculate the precision, recall, and f1-score for SVM\n",
    "cr_svm = classification_report(y_test, y_pred_svm, zero_division=1)\n",
    "print(\"\\nClassification report for Support Vector Machine (SVM):\\n\", cr_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "683e39f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.04346966743469238 seconds\n",
      "\n",
      "Classification report for Support Vector Machine (SVM):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       897\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1758\n",
      "   macro avg       1.00      1.00      1.00      1758\n",
      "weighted avg       1.00      1.00      1.00      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM using scikit-learn's SVC with under sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using undersampling with the RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X, y = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "#Train the Support Vector Machine (SVM) model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "#Predict the test set using SVM\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "#Calculate the precision, recall, and f1-score for SVM\n",
    "cr_svm = classification_report(y_test, y_pred_svm, zero_division=1)\n",
    "print(\"\\nClassification report for Support Vector Machine (SVM):\\n\", cr_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b06a74c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 1.1196284294128418 seconds\n",
      "\n",
      "Classification report for Neural Network:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       895\n",
      "           1       1.00      1.00      1.00      1330\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks using scikit-learn's MLPClassifier without sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Train the Neural Network model\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the test set using Neural Network\n",
    "y_pred_nn = nn.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "#Calculate the precision, recall, and f1-score for Neural Network\n",
    "cr_nn = classification_report(y_test, y_pred_nn, zero_division=1)\n",
    "print(\"\\nClassification report for Neural Network:\\n\", cr_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2a48b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 1.2622435092926025 seconds\n",
      "\n",
      "Classification report for Neural Network:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1339\n",
      "           1       1.00      1.00      1.00      1353\n",
      "\n",
      "    accuracy                           1.00      2692\n",
      "   macro avg       1.00      1.00      1.00      2692\n",
      "weighted avg       1.00      1.00      1.00      2692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks using scikit-learn's MLPClassifier with over sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Train the Neural Network model\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the test set using Neural Network\n",
    "y_pred_nn = nn.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "#Calculate the precision, recall, and f1-score for Neural Network\n",
    "cr_nn = classification_report(y_test, y_pred_nn, zero_division=1)\n",
    "print(\"\\nClassification report for Neural Network:\\n\", cr_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84df335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 1.0640242099761963 seconds\n",
      "\n",
      "Classification report for Neural Network:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       894\n",
      "           1       1.00      1.00      1.00       864\n",
      "\n",
      "    accuracy                           1.00      1758\n",
      "   macro avg       1.00      1.00      1.00      1758\n",
      "weighted avg       1.00      1.00      1.00      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks using scikit-learn's MLPClassifier with under sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using undersampling with the RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X, y = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Train the Neural Network model\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the test set using Neural Network\n",
    "y_pred_nn = nn.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "#Calculate the precision, recall, and f1-score for Neural Network\n",
    "cr_nn = classification_report(y_test, y_pred_nn, zero_division=1)\n",
    "print(\"\\nClassification report for Neural Network:\\n\", cr_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb0a06ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.17416787147521973 seconds\n",
      "\n",
      "Classification report for K-Nearest Neighbors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       873\n",
      "           1       1.00      1.00      1.00      1352\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Knn no sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the K-Nearest Neighbors model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set using K-Nearest Neighbors\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for K-Nearest Neighbors\n",
    "cr_knn = classification_report(y_test, y_pred_knn)\n",
    "print(\"\\nClassification report for K-Nearest Neighbors:\\n\", cr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4104bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.19349360466003418 seconds\n",
      "\n",
      "Classification report for K-Nearest Neighbors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1366\n",
      "           1       1.00      1.00      1.00      1326\n",
      "\n",
      "    accuracy                           1.00      2692\n",
      "   macro avg       1.00      1.00      1.00      2692\n",
      "weighted avg       1.00      1.00      1.00      2692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Knn over sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the K-Nearest Neighbors model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set using K-Nearest Neighbors\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for K-Nearest Neighbors\n",
    "cr_knn = classification_report(y_test, y_pred_knn)\n",
    "print(\"\\nClassification report for K-Nearest Neighbors:\\n\", cr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6acd231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.11568403244018555 seconds\n",
      "\n",
      "Classification report for K-Nearest Neighbors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       908\n",
      "           1       1.00      1.00      1.00       850\n",
      "\n",
      "    accuracy                           1.00      1758\n",
      "   macro avg       1.00      1.00      1.00      1758\n",
      "weighted avg       1.00      1.00      1.00      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Knn under sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using undersampling with the RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X, y = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the K-Nearest Neighbors model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set using K-Nearest Neighbors\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for K-Nearest Neighbors\n",
    "cr_knn = classification_report(y_test, y_pred_knn)\n",
    "print(\"\\nClassification report for K-Nearest Neighbors:\\n\", cr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "488d38c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "279/279 [==============================] - 1s 1ms/step - loss: 27711.3672 - val_loss: 0.0234\n",
      "Epoch 2/100\n",
      "279/279 [==============================] - 0s 983us/step - loss: 0.0230 - val_loss: 0.0225\n",
      "Epoch 3/100\n",
      "279/279 [==============================] - 0s 903us/step - loss: 0.0220 - val_loss: 0.0213\n",
      "Epoch 4/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.0199\n",
      "Epoch 5/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0183\n",
      "Epoch 6/100\n",
      "279/279 [==============================] - 0s 925us/step - loss: 0.0174 - val_loss: 0.0164\n",
      "Epoch 7/100\n",
      "279/279 [==============================] - 0s 964us/step - loss: 0.0155 - val_loss: 0.0146\n",
      "Epoch 8/100\n",
      "279/279 [==============================] - 0s 904us/step - loss: 0.0136 - val_loss: 0.0126\n",
      "Epoch 9/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 10/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 11/100\n",
      "279/279 [==============================] - 0s 979us/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 12/100\n",
      "279/279 [==============================] - 0s 943us/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 13/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 14/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.1147 - val_loss: 0.3091\n",
      "Epoch 15/100\n",
      "279/279 [==============================] - 0s 976us/step - loss: 0.0277 - val_loss: 0.0020\n",
      "Epoch 16/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 17/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 1.0035 - val_loss: 6.8073e-04\n",
      "Epoch 18/100\n",
      "279/279 [==============================] - 0s 998us/step - loss: 5.1606e-04 - val_loss: 3.7053e-04\n",
      "Epoch 19/100\n",
      "279/279 [==============================] - 0s 958us/step - loss: 2.6943e-04 - val_loss: 1.8665e-04\n",
      "Epoch 20/100\n",
      "279/279 [==============================] - 0s 959us/step - loss: 1.2864e-04 - val_loss: 8.2256e-05\n",
      "Epoch 21/100\n",
      "279/279 [==============================] - 0s 960us/step - loss: 1.1395e-04 - val_loss: 7.0256e-04\n",
      "Epoch 22/100\n",
      "279/279 [==============================] - 0s 932us/step - loss: 0.8698 - val_loss: 1.9666e-05\n",
      "Epoch 23/100\n",
      "279/279 [==============================] - 0s 925us/step - loss: 1.0763e-05 - val_loss: 5.5189e-06\n",
      "Epoch 24/100\n",
      "279/279 [==============================] - 0s 942us/step - loss: 7.8912e-06 - val_loss: 4.8607e-06\n",
      "Epoch 25/100\n",
      "279/279 [==============================] - 0s 941us/step - loss: 0.0086 - val_loss: 2.8234e-04\n",
      "Epoch 26/100\n",
      "279/279 [==============================] - 0s 935us/step - loss: 0.4015 - val_loss: 8.8689\n",
      "Epoch 27/100\n",
      "279/279 [==============================] - 0s 934us/step - loss: 1.0387 - val_loss: 3.6773e-05\n",
      "Epoch 28/100\n",
      "279/279 [==============================] - 0s 967us/step - loss: 2.7714e-06 - val_loss: 9.0059e-07\n",
      "Epoch 29/100\n",
      "279/279 [==============================] - 0s 959us/step - loss: 7.8169e-04 - val_loss: 0.0202\n",
      "Epoch 30/100\n",
      "279/279 [==============================] - 0s 903us/step - loss: 5.0309 - val_loss: 0.0290\n",
      "Epoch 31/100\n",
      "279/279 [==============================] - 0s 979us/step - loss: 0.0465 - val_loss: 6.8078e-06\n",
      "Epoch 32/100\n",
      "279/279 [==============================] - 0s 917us/step - loss: 0.6698 - val_loss: 8.5936\n",
      "Epoch 33/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 4.0876 - val_loss: 6.9618e-06\n",
      "Epoch 34/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 1.5984e-06 - val_loss: 7.1592e-07\n",
      "Epoch 35/100\n",
      "279/279 [==============================] - 0s 975us/step - loss: 6.8839e-07 - val_loss: 9.9101e-07\n",
      "Epoch 36/100\n",
      "279/279 [==============================] - 0s 968us/step - loss: 2.9532e-06 - val_loss: 5.8213e-07\n",
      "Epoch 37/100\n",
      "279/279 [==============================] - 0s 987us/step - loss: 0.7949 - val_loss: 0.0252\n",
      "Epoch 38/100\n",
      "279/279 [==============================] - 0s 967us/step - loss: 0.6156 - val_loss: 6.8247\n",
      "Epoch 39/100\n",
      "279/279 [==============================] - 0s 956us/step - loss: 4.7355 - val_loss: 1.1420e-04\n",
      "Epoch 40/100\n",
      "279/279 [==============================] - 0s 965us/step - loss: 7.5797e-06 - val_loss: 1.0333e-06\n",
      "Epoch 41/100\n",
      "279/279 [==============================] - 0s 965us/step - loss: 1.2314e-06 - val_loss: 3.9187e-06\n",
      "Epoch 42/100\n",
      "279/279 [==============================] - 0s 978us/step - loss: 2.3646 - val_loss: 0.9224\n",
      "Epoch 43/100\n",
      "279/279 [==============================] - 0s 959us/step - loss: 0.1091 - val_loss: 0.0043\n",
      "Epoch 44/100\n",
      "279/279 [==============================] - 0s 970us/step - loss: 0.0029 - val_loss: 4.6745e-05\n",
      "Epoch 45/100\n",
      "279/279 [==============================] - 0s 982us/step - loss: 6.1788 - val_loss: 0.4478\n",
      "Epoch 46/100\n",
      "279/279 [==============================] - 0s 936us/step - loss: 0.0258 - val_loss: 6.3286e-06\n",
      "Epoch 47/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 2.5354e-06 - val_loss: 1.1083e-05\n",
      "Epoch 48/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0894\n",
      "Epoch 49/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 3.0978 - val_loss: 13.8879\n",
      "Epoch 50/100\n",
      "279/279 [==============================] - 0s 998us/step - loss: 0.6600 - val_loss: 7.6678e-06\n",
      "Epoch 51/100\n",
      "279/279 [==============================] - 0s 996us/step - loss: 2.2897e-06 - val_loss: 7.5957e-07\n",
      "Epoch 52/100\n",
      "279/279 [==============================] - 0s 990us/step - loss: 1.2908e-05 - val_loss: 0.0067\n",
      "Epoch 53/100\n",
      "279/279 [==============================] - 0s 928us/step - loss: 12.8897 - val_loss: 0.1075\n",
      "Epoch 54/100\n",
      "279/279 [==============================] - 0s 915us/step - loss: 0.0027 - val_loss: 1.0946e-05\n",
      "Epoch 55/100\n",
      "279/279 [==============================] - 0s 974us/step - loss: 5.8322e-06 - val_loss: 4.1774e-06\n",
      "Epoch 56/100\n",
      "279/279 [==============================] - 0s 929us/step - loss: 1.2882e-06 - val_loss: 5.1216e-07\n",
      "Epoch 57/100\n",
      "279/279 [==============================] - 0s 916us/step - loss: 2.6224e-07 - val_loss: 1.1832e-06\n",
      "Epoch 58/100\n",
      "279/279 [==============================] - 0s 942us/step - loss: 6.4544e-06 - val_loss: 6.0813e-05\n",
      "Epoch 59/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 2.0623 - val_loss: 0.7824\n",
      "Epoch 60/100\n",
      "279/279 [==============================] - 0s 994us/step - loss: 0.0390 - val_loss: 2.9004e-06\n",
      "Epoch 61/100\n",
      "279/279 [==============================] - 0s 922us/step - loss: 2.2046e-06 - val_loss: 2.9934e-06\n",
      "Epoch 62/100\n",
      "279/279 [==============================] - 0s 991us/step - loss: 1.8647 - val_loss: 0.0129\n",
      "Epoch 63/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 3.0503e-04 - val_loss: 4.9686e-07\n",
      "Epoch 64/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 1.5332e-07 - val_loss: 2.7669e-07\n",
      "Epoch 65/100\n",
      "279/279 [==============================] - 0s 991us/step - loss: 0.0088 - val_loss: 0.0717\n",
      "Epoch 66/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 12.3752 - val_loss: 3.8414e-06\n",
      "Epoch 67/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 3.8321e-06 - val_loss: 5.4996e-07\n",
      "Epoch 68/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 5.8410e-07 - val_loss: 2.3902e-06\n",
      "Epoch 69/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.6979 - val_loss: 3.0050\n",
      "Epoch 70/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.1260 - val_loss: 1.8637e-06\n",
      "Epoch 71/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 3.7817e-05 - val_loss: 0.0073\n",
      "Epoch 72/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1003\n",
      "Epoch 73/100\n",
      "279/279 [==============================] - 0s 932us/step - loss: 0.4613 - val_loss: 0.0812\n",
      "Epoch 74/100\n",
      "279/279 [==============================] - 0s 912us/step - loss: 0.5559 - val_loss: 0.4993\n",
      "Epoch 75/100\n",
      "279/279 [==============================] - 0s 942us/step - loss: 5.0024 - val_loss: 0.0015\n",
      "Epoch 76/100\n",
      "279/279 [==============================] - 0s 920us/step - loss: 1.6656e-04 - val_loss: 2.8430e-06\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 0s 966us/step - loss: 1.3078e-06 - val_loss: 8.6533e-06\n",
      "Epoch 78/100\n",
      "279/279 [==============================] - 0s 925us/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 79/100\n",
      "279/279 [==============================] - 0s 903us/step - loss: 1.9312 - val_loss: 12.5860\n",
      "Epoch 80/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.4327 - val_loss: 5.7940e-06\n",
      "Epoch 81/100\n",
      "279/279 [==============================] - 0s 951us/step - loss: 0.0076 - val_loss: 0.0945\n",
      "Epoch 82/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 5.1005 - val_loss: 0.0105\n",
      "Epoch 83/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 6.9441e-04 - val_loss: 1.1248e-05\n",
      "Epoch 84/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 4.3814e-06 - val_loss: 1.1198e-06\n",
      "Epoch 85/100\n",
      "279/279 [==============================] - 0s 945us/step - loss: 1.0251e-06 - val_loss: 4.3392e-06\n",
      "Epoch 86/100\n",
      "279/279 [==============================] - 0s 932us/step - loss: 1.2296e-06 - val_loss: 5.5301e-07\n",
      "Epoch 87/100\n",
      "279/279 [==============================] - 0s 971us/step - loss: 0.0218 - val_loss: 0.0237\n",
      "Epoch 88/100\n",
      "279/279 [==============================] - 0s 962us/step - loss: 2.5655 - val_loss: 0.0427\n",
      "Epoch 89/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0060\n",
      "Epoch 90/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.4340\n",
      "Epoch 91/100\n",
      "279/279 [==============================] - 0s 988us/step - loss: 4.3927 - val_loss: 0.1311\n",
      "Epoch 92/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 7.9809e-07\n",
      "Epoch 93/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 2.1358e-07 - val_loss: 5.8781e-08\n",
      "Epoch 94/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 5.4120e-08 - val_loss: 1.3609e-06\n",
      "Epoch 95/100\n",
      "279/279 [==============================] - 0s 973us/step - loss: 0.5230 - val_loss: 0.0037\n",
      "Epoch 96/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.1448 - val_loss: 2.8681\n",
      "Epoch 97/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 8.0000 - val_loss: 1.5132e-05\n",
      "Epoch 98/100\n",
      "279/279 [==============================] - 0s 985us/step - loss: 2.5106e-06 - val_loss: 1.3957e-07\n",
      "Epoch 99/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 2.3833e-07 - val_loss: 2.2602e-07\n",
      "Epoch 100/100\n",
      "279/279 [==============================] - 0s 982us/step - loss: 0.0600 - val_loss: 2.6143\n",
      "Computational time: 29.78360152244568 seconds\n",
      "\n",
      "Classification report for Autoencoder with K-Nearest Neighbors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       882\n",
      "           1       1.00      1.00      1.00      1343\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Note: Autoencoders are not classifiers, so it's not possible to calculate a classification report for them. \n",
    "#To use autoencoders in this context, you would need to first train the autoencoder to learn a compact representation\n",
    "#of the input data, and then use this representation as input to another machine learning model, \n",
    "#such as a classifier, for prediction.\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "autoencoder.add(Dense(units=32, activation='relu'))\n",
    "autoencoder.add(Dense(units=64, activation='relu'))\n",
    "autoencoder.add(Dense(units=X_train.shape[1]))\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder model\n",
    "autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_test, X_test))\n",
    "\n",
    "# Use the autoencoder to encode the training and testing data\n",
    "X_train_encoded = autoencoder.predict(X_train)\n",
    "X_test_encoded = autoencoder.predict(X_test)\n",
    "\n",
    "# Train the K-Nearest Neighbors model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predict the test set using K-Nearest Neighbors\n",
    "y_pred_knn = knn.predict(X_test_encoded)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for K-Nearest Neighbors\n",
    "cr_knn = classification_report(y_test, y_pred_knn)\n",
    "print(\"\\nClassification report for Autoencoder with K-Nearest Neighbors:\\n\", cr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "595abfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "279/279 [==============================] - 1s 1ms/step - loss: 24825.9512 - val_loss: 0.0176\n",
      "Epoch 2/100\n",
      "279/279 [==============================] - 0s 954us/step - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 3/100\n",
      "279/279 [==============================] - 0s 930us/step - loss: 0.0164 - val_loss: 0.0159\n",
      "Epoch 4/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0152\n",
      "Epoch 5/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.1541 - val_loss: 0.6656\n",
      "Epoch 6/100\n",
      "279/279 [==============================] - 0s 992us/step - loss: 0.0540 - val_loss: 0.0120\n",
      "Epoch 7/100\n",
      "279/279 [==============================] - 0s 973us/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 8/100\n",
      "279/279 [==============================] - 0s 939us/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 9/100\n",
      "279/279 [==============================] - 0s 960us/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 10/100\n",
      "279/279 [==============================] - 0s 923us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 11/100\n",
      "279/279 [==============================] - 0s 958us/step - loss: 0.0127 - val_loss: 0.0448\n",
      "Epoch 12/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.1301 - val_loss: 0.0742\n",
      "Epoch 13/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0025\n",
      "Epoch 14/100\n",
      "279/279 [==============================] - 0s 982us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 15/100\n",
      "279/279 [==============================] - 0s 968us/step - loss: 0.4935 - val_loss: 0.0893\n",
      "Epoch 16/100\n",
      "279/279 [==============================] - 0s 978us/step - loss: 0.0368 - val_loss: 6.6425e-04\n",
      "Epoch 17/100\n",
      "279/279 [==============================] - 0s 952us/step - loss: 0.0073 - val_loss: 1.1743\n",
      "Epoch 18/100\n",
      "279/279 [==============================] - 0s 973us/step - loss: 0.9715 - val_loss: 6.1971e-04\n",
      "Epoch 19/100\n",
      "279/279 [==============================] - 0s 988us/step - loss: 1.5094e-04 - val_loss: 8.9676e-05\n",
      "Epoch 20/100\n",
      "279/279 [==============================] - 0s 973us/step - loss: 6.4328e-05 - val_loss: 3.5584e-05\n",
      "Epoch 21/100\n",
      "279/279 [==============================] - 0s 923us/step - loss: 2.3005e-05 - val_loss: 1.4676e-05\n",
      "Epoch 22/100\n",
      "279/279 [==============================] - 0s 950us/step - loss: 0.0070 - val_loss: 0.3102\n",
      "Epoch 23/100\n",
      "279/279 [==============================] - 0s 961us/step - loss: 2.3075 - val_loss: 0.0015\n",
      "Epoch 24/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 6.8596e-05 - val_loss: 9.4813e-07\n",
      "Epoch 25/100\n",
      "279/279 [==============================] - 0s 930us/step - loss: 5.1477e-07 - val_loss: 7.9058e-07\n",
      "Epoch 26/100\n",
      "279/279 [==============================] - 0s 929us/step - loss: 9.5034e-05 - val_loss: 5.6384e-06\n",
      "Epoch 27/100\n",
      "279/279 [==============================] - 0s 956us/step - loss: 0.5729 - val_loss: 76.8551\n",
      "Epoch 28/100\n",
      "279/279 [==============================] - 0s 951us/step - loss: 4.6483 - val_loss: 1.7132e-05\n",
      "Epoch 29/100\n",
      "279/279 [==============================] - 0s 959us/step - loss: 0.0659 - val_loss: 0.6522\n",
      "Epoch 30/100\n",
      "279/279 [==============================] - 0s 969us/step - loss: 4.8600 - val_loss: 8.3490e-04\n",
      "Epoch 31/100\n",
      "279/279 [==============================] - 0s 937us/step - loss: 3.8602e-05 - val_loss: 8.0093e-07\n",
      "Epoch 32/100\n",
      "279/279 [==============================] - 0s 962us/step - loss: 3.4625e-07 - val_loss: 8.3325e-08\n",
      "Epoch 33/100\n",
      "279/279 [==============================] - 0s 969us/step - loss: 4.0837e-07 - val_loss: 4.3710e-06\n",
      "Epoch 34/100\n",
      "279/279 [==============================] - 0s 965us/step - loss: 0.0170 - val_loss: 0.0636\n",
      "Epoch 35/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 2.8167 - val_loss: 0.5886\n",
      "Epoch 36/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 1.3130 - val_loss: 4.7706e-04\n",
      "Epoch 37/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 6.8188e-05 - val_loss: 2.1872e-06\n",
      "Epoch 38/100\n",
      "279/279 [==============================] - 0s 996us/step - loss: 0.1196 - val_loss: 6.0075\n",
      "Epoch 39/100\n",
      "279/279 [==============================] - 0s 952us/step - loss: 8.4145 - val_loss: 0.0172\n",
      "Epoch 40/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 3.7250e-04 - val_loss: 4.5590e-05\n",
      "Epoch 41/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 1.7871e-05 - val_loss: 7.3683e-06\n",
      "Epoch 42/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 4.0728e-06 - val_loss: 7.4960e-07\n",
      "Epoch 43/100\n",
      "279/279 [==============================] - 0s 966us/step - loss: 0.5521 - val_loss: 2.0964\n",
      "Epoch 44/100\n",
      "279/279 [==============================] - 0s 976us/step - loss: 0.1044 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "279/279 [==============================] - 0s 943us/step - loss: 3.9554 - val_loss: 0.0257\n",
      "Epoch 46/100\n",
      "279/279 [==============================] - 0s 947us/step - loss: 9.7886e-04 - val_loss: 3.2462e-06\n",
      "Epoch 47/100\n",
      "279/279 [==============================] - 0s 962us/step - loss: 1.5820e-05 - val_loss: 0.0041\n",
      "Epoch 48/100\n",
      "279/279 [==============================] - 0s 973us/step - loss: 3.9900e-04 - val_loss: 0.3527\n",
      "Epoch 49/100\n",
      "279/279 [==============================] - 0s 962us/step - loss: 7.0464 - val_loss: 0.0768\n",
      "Epoch 50/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 3.3192e-06\n",
      "Epoch 51/100\n",
      "279/279 [==============================] - 0s 994us/step - loss: 2.1132e-06 - val_loss: 2.7353e-06\n",
      "Epoch 52/100\n",
      "279/279 [==============================] - 0s 974us/step - loss: 1.3815e-06 - val_loss: 2.0276e-07\n",
      "Epoch 53/100\n",
      "279/279 [==============================] - 0s 997us/step - loss: 1.0773e-06 - val_loss: 3.4943e-05\n",
      "Epoch 54/100\n",
      "279/279 [==============================] - 0s 968us/step - loss: 2.8164 - val_loss: 8.9958\n",
      "Epoch 55/100\n",
      "279/279 [==============================] - 0s 946us/step - loss: 5.9063 - val_loss: 0.0081\n",
      "Epoch 56/100\n",
      "279/279 [==============================] - 0s 945us/step - loss: 5.8773e-04 - val_loss: 3.1831e-07\n",
      "Epoch 57/100\n",
      "279/279 [==============================] - 0s 971us/step - loss: 2.1866e-07 - val_loss: 6.3108e-08\n",
      "Epoch 58/100\n",
      "279/279 [==============================] - 0s 935us/step - loss: 1.5232e-07 - val_loss: 1.3839e-06\n",
      "Epoch 59/100\n",
      "279/279 [==============================] - 0s 923us/step - loss: 8.7888e-06 - val_loss: 1.5760e-05\n",
      "Epoch 60/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 2.9121 - val_loss: 6.8232\n",
      "Epoch 61/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.1619 - val_loss: 0.0013\n",
      "Epoch 62/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 6.4687 - val_loss: 0.0070\n",
      "Epoch 63/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 6.8597e-06\n",
      "Epoch 64/100\n",
      "279/279 [==============================] - 0s 981us/step - loss: 5.3054e-06 - val_loss: 9.6647e-05\n",
      "Epoch 65/100\n",
      "279/279 [==============================] - 0s 942us/step - loss: 0.0272 - val_loss: 0.0559\n",
      "Epoch 66/100\n",
      "279/279 [==============================] - 0s 981us/step - loss: 0.4664 - val_loss: 0.0154\n",
      "Epoch 67/100\n",
      "279/279 [==============================] - 0s 966us/step - loss: 1.6205 - val_loss: 6.1285\n",
      "Epoch 68/100\n",
      "279/279 [==============================] - 0s 961us/step - loss: 5.6542 - val_loss: 1.4322e-05\n",
      "Epoch 69/100\n",
      "279/279 [==============================] - 0s 974us/step - loss: 7.9556e-06 - val_loss: 2.3946e-06\n",
      "Epoch 70/100\n",
      "279/279 [==============================] - ETA: 0s - loss: 1.1170e-0 - 0s 1ms/step - loss: 9.7426e-07 - val_loss: 5.4039e-07\n",
      "Epoch 71/100\n",
      "279/279 [==============================] - 0s 961us/step - loss: 6.2698e-07 - val_loss: 3.1815e-06\n",
      "Epoch 72/100\n",
      "279/279 [==============================] - 0s 996us/step - loss: 3.1136 - val_loss: 3.2795\n",
      "Epoch 73/100\n",
      "279/279 [==============================] - 0s 950us/step - loss: 1.1458 - val_loss: 4.3520\n",
      "Epoch 74/100\n",
      "279/279 [==============================] - 0s 961us/step - loss: 0.2022 - val_loss: 1.9353e-04\n",
      "Epoch 75/100\n",
      "279/279 [==============================] - 0s 956us/step - loss: 0.0036 - val_loss: 0.0384\n",
      "Epoch 76/100\n",
      "279/279 [==============================] - 0s 966us/step - loss: 0.6323 - val_loss: 0.0038\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 0s 980us/step - loss: 5.9791 - val_loss: 0.0035\n",
      "Epoch 78/100\n",
      "279/279 [==============================] - 0s 924us/step - loss: 6.5854e-04 - val_loss: 1.9854e-06\n",
      "Epoch 79/100\n",
      "279/279 [==============================] - 0s 938us/step - loss: 0.0343 - val_loss: 2.8724\n",
      "Epoch 80/100\n",
      "279/279 [==============================] - 0s 937us/step - loss: 0.3997 - val_loss: 0.0401\n",
      "Epoch 81/100\n",
      "279/279 [==============================] - 0s 917us/step - loss: 0.3586 - val_loss: 9.5172e-04\n",
      "Epoch 82/100\n",
      "279/279 [==============================] - 0s 959us/step - loss: 0.0143 - val_loss: 9.7048e-05\n",
      "Epoch 83/100\n",
      "279/279 [==============================] - 0s 964us/step - loss: 4.8341 - val_loss: 0.7034\n",
      "Epoch 84/100\n",
      "279/279 [==============================] - 0s 957us/step - loss: 0.0416 - val_loss: 0.2490\n",
      "Epoch 85/100\n",
      "279/279 [==============================] - 0s 992us/step - loss: 0.0591 - val_loss: 1.5293\n",
      "Epoch 86/100\n",
      "279/279 [==============================] - 0s 964us/step - loss: 3.7784 - val_loss: 1.3581e-05\n",
      "Epoch 87/100\n",
      "279/279 [==============================] - 0s 987us/step - loss: 7.6181e-06 - val_loss: 1.5458e-04\n",
      "Epoch 88/100\n",
      "279/279 [==============================] - 0s 958us/step - loss: 2.4495e-05 - val_loss: 4.9999e-05\n",
      "Epoch 89/100\n",
      "279/279 [==============================] - 0s 968us/step - loss: 1.1274 - val_loss: 10.4426\n",
      "Epoch 90/100\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.399 - 0s 961us/step - loss: 0.3623 - val_loss: 5.1585e-07\n",
      "Epoch 91/100\n",
      "279/279 [==============================] - 0s 964us/step - loss: 1.3436e-04 - val_loss: 1.1269e-06\n",
      "Epoch 92/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 6.5881 - val_loss: 3.3563e-04\n",
      "Epoch 93/100\n",
      "279/279 [==============================] - 0s 971us/step - loss: 2.3565e-05 - val_loss: 6.2801e-06\n",
      "Epoch 94/100\n",
      "279/279 [==============================] - 0s 975us/step - loss: 1.2257e-05 - val_loss: 3.4296e-04\n",
      "Epoch 95/100\n",
      "279/279 [==============================] - 0s 973us/step - loss: 0.6845 - val_loss: 0.0727\n",
      "Epoch 96/100\n",
      "279/279 [==============================] - 0s 998us/step - loss: 1.3357 - val_loss: 0.0921\n",
      "Epoch 97/100\n",
      "279/279 [==============================] - 0s 960us/step - loss: 0.0160 - val_loss: 0.0743\n",
      "Epoch 98/100\n",
      "279/279 [==============================] - 0s 972us/step - loss: 0.0346 - val_loss: 0.4682\n",
      "Epoch 99/100\n",
      "279/279 [==============================] - 0s 982us/step - loss: 11.7041 - val_loss: 0.0203\n",
      "Epoch 100/100\n",
      "279/279 [==============================] - 0s 983us/step - loss: 0.0012 - val_loss: 7.2061e-05\n",
      "Computational time: 28.236315488815308 seconds\n",
      "\n",
      "Classification report for Autoencoder with K-Nearest Neighbors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       879\n",
      "           1       1.00      1.00      1.00      1346\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Autoencoder with over sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Balance the dataset using RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "autoencoder.add(Dense(units=32, activation='relu'))\n",
    "autoencoder.add(Dense(units=64, activation='relu'))\n",
    "autoencoder.add(Dense(units=X_train.shape[1]))\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder model\n",
    "autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_test, X_test))\n",
    "\n",
    "# Use the autoencoder to encode the training and testing data\n",
    "X_train_encoded = autoencoder.predict(X_train)\n",
    "X_test_encoded = autoencoder.predict(X_test)\n",
    "\n",
    "# Train the K-Nearest Neighbors model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predict the test set using K-Nearest Neighbors\n",
    "y_pred_knn = knn.predict(X_test_encoded)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for K-Nearest Neighbors\n",
    "cr_knn = classification_report(y_test, y_pred_knn)\n",
    "print(\"\\nClassification report for Autoencoder with K-Nearest Neighbors:\\n\", cr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15470b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "279/279 [==============================] - 1s 1ms/step - loss: 15354.3105 - val_loss: 0.0160\n",
      "Epoch 2/100\n",
      "279/279 [==============================] - 0s 932us/step - loss: 0.0154 - val_loss: 0.0152\n",
      "Epoch 3/100\n",
      "279/279 [==============================] - 0s 950us/step - loss: 0.0145 - val_loss: 0.0142\n",
      "Epoch 4/100\n",
      "279/279 [==============================] - 0s 937us/step - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 5/100\n",
      "279/279 [==============================] - 0s 931us/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 6/100\n",
      "279/279 [==============================] - 0s 925us/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 7/100\n",
      "279/279 [==============================] - 0s 933us/step - loss: 0.0093 - val_loss: 0.0088\n",
      "Epoch 8/100\n",
      "279/279 [==============================] - 0s 943us/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 9/100\n",
      "279/279 [==============================] - 0s 938us/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 10/100\n",
      "279/279 [==============================] - 0s 922us/step - loss: 0.0107 - val_loss: 0.0046\n",
      "Epoch 11/100\n",
      "279/279 [==============================] - 0s 940us/step - loss: 0.2394 - val_loss: 0.0036\n",
      "Epoch 12/100\n",
      "279/279 [==============================] - 0s 942us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 13/100\n",
      "279/279 [==============================] - 0s 929us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 14/100\n",
      "279/279 [==============================] - 0s 921us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 15/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.4648 - val_loss: 6.4450\n",
      "Epoch 16/100\n",
      "279/279 [==============================] - 0s 922us/step - loss: 0.3714 - val_loss: 3.3128e-04\n",
      "Epoch 17/100\n",
      "279/279 [==============================] - 0s 961us/step - loss: 2.4242e-04 - val_loss: 1.7157e-04\n",
      "Epoch 18/100\n",
      "279/279 [==============================] - 0s 925us/step - loss: 1.1820e-04 - val_loss: 7.6640e-05\n",
      "Epoch 19/100\n",
      "279/279 [==============================] - 0s 928us/step - loss: 5.3192e-05 - val_loss: 3.9497e-05\n",
      "Epoch 20/100\n",
      "279/279 [==============================] - 0s 910us/step - loss: 0.3156 - val_loss: 5.0853e-05\n",
      "Epoch 21/100\n",
      "279/279 [==============================] - 0s 937us/step - loss: 3.3727e-04 - val_loss: 0.0127\n",
      "Epoch 22/100\n",
      "279/279 [==============================] - 0s 956us/step - loss: 3.0241 - val_loss: 1.1462e-05\n",
      "Epoch 23/100\n",
      "279/279 [==============================] - 0s 948us/step - loss: 7.8933e-07 - val_loss: 1.9778e-07\n",
      "Epoch 24/100\n",
      "279/279 [==============================] - 0s 942us/step - loss: 1.3047e-07 - val_loss: 1.2563e-07\n",
      "Epoch 25/100\n",
      "279/279 [==============================] - 0s 924us/step - loss: 7.5577e-07 - val_loss: 5.8772e-06\n",
      "Epoch 26/100\n",
      "279/279 [==============================] - 0s 959us/step - loss: 2.5193 - val_loss: 0.4326\n",
      "Epoch 27/100\n",
      "279/279 [==============================] - 0s 911us/step - loss: 0.2554 - val_loss: 7.2072e-06\n",
      "Epoch 28/100\n",
      "279/279 [==============================] - 0s 944us/step - loss: 0.1385 - val_loss: 1.1570\n",
      "Epoch 29/100\n",
      "279/279 [==============================] - 0s 899us/step - loss: 11.1496 - val_loss: 5.8030e-06\n",
      "Epoch 30/100\n",
      "279/279 [==============================] - 0s 929us/step - loss: 3.3106e-06 - val_loss: 1.4544e-05\n",
      "Epoch 31/100\n",
      "279/279 [==============================] - 0s 944us/step - loss: 1.8063e-06 - val_loss: 1.2753e-06\n",
      "Epoch 32/100\n",
      "279/279 [==============================] - 0s 936us/step - loss: 6.8727e-07 - val_loss: 2.3491e-07\n",
      "Epoch 33/100\n",
      "279/279 [==============================] - 0s 942us/step - loss: 0.0143 - val_loss: 0.2397\n",
      "Epoch 34/100\n",
      "279/279 [==============================] - 0s 942us/step - loss: 3.9411 - val_loss: 0.5082\n",
      "Epoch 35/100\n",
      "279/279 [==============================] - 0s 932us/step - loss: 0.2075 - val_loss: 1.5025\n",
      "Epoch 36/100\n",
      "279/279 [==============================] - 0s 978us/step - loss: 0.0703 - val_loss: 0.1148\n",
      "Epoch 37/100\n",
      "279/279 [==============================] - 0s 969us/step - loss: 2.3989 - val_loss: 3.2945\n",
      "Epoch 38/100\n",
      "279/279 [==============================] - 0s 980us/step - loss: 0.1968 - val_loss: 0.0024\n",
      "Epoch 39/100\n",
      "279/279 [==============================] - 0s 981us/step - loss: 0.1233 - val_loss: 2.3932\n",
      "Epoch 40/100\n",
      "279/279 [==============================] - 0s 971us/step - loss: 3.7535 - val_loss: 1.8716e-04\n",
      "Epoch 41/100\n",
      "279/279 [==============================] - 0s 986us/step - loss: 0.0993 - val_loss: 0.0584\n",
      "Epoch 42/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 7.0196 - val_loss: 0.0017\n",
      "Epoch 43/100\n",
      "279/279 [==============================] - 0s 972us/step - loss: 1.9048e-04 - val_loss: 6.6679e-07\n",
      "Epoch 44/100\n",
      "279/279 [==============================] - 0s 931us/step - loss: 5.3460e-07 - val_loss: 2.2484e-07\n",
      "Epoch 45/100\n",
      "279/279 [==============================] - 0s 967us/step - loss: 1.7562e-07 - val_loss: 9.7438e-08\n",
      "Epoch 46/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 4.8721e-07 - val_loss: 1.5969e-06\n",
      "Epoch 47/100\n",
      "279/279 [==============================] - 0s 950us/step - loss: 1.4350 - val_loss: 1062.8267\n",
      "Epoch 48/100\n",
      "279/279 [==============================] - 0s 952us/step - loss: 22.0654 - val_loss: 7.8996e-06\n",
      "Epoch 49/100\n",
      "279/279 [==============================] - 0s 974us/step - loss: 4.6576e-06 - val_loss: 3.5904e-06\n",
      "Epoch 50/100\n",
      "279/279 [==============================] - 0s 977us/step - loss: 1.4546e-06 - val_loss: 1.4808e-06\n",
      "Epoch 51/100\n",
      "279/279 [==============================] - 0s 978us/step - loss: 7.7444e-07 - val_loss: 2.2925e-07\n",
      "Epoch 52/100\n",
      "279/279 [==============================] - 0s 943us/step - loss: 8.8278e-05 - val_loss: 7.5509e-06\n",
      "Epoch 53/100\n",
      "279/279 [==============================] - 0s 982us/step - loss: 0.9442 - val_loss: 2.2738\n",
      "Epoch 54/100\n",
      "279/279 [==============================] - 0s 955us/step - loss: 2.6521 - val_loss: 6.2423e-06\n",
      "Epoch 55/100\n",
      "279/279 [==============================] - 0s 981us/step - loss: 3.5703e-06 - val_loss: 1.4095e-06\n",
      "Epoch 56/100\n",
      "279/279 [==============================] - 0s 965us/step - loss: 7.1088e-07 - val_loss: 6.8934e-07\n",
      "Epoch 57/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 1.2551e-06 - val_loss: 5.9623e-06\n",
      "Epoch 58/100\n",
      "279/279 [==============================] - 0s 927us/step - loss: 3.7766 - val_loss: 1.9901\n",
      "Epoch 59/100\n",
      "279/279 [==============================] - 0s 943us/step - loss: 0.8950 - val_loss: 0.0016\n",
      "Epoch 60/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 4.8677e-05 - val_loss: 2.0880e-06\n",
      "Epoch 61/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 2.2922e-06 - val_loss: 1.2936e-06\n",
      "Epoch 62/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 17.5924 - val_loss: 0.2343\n",
      "Epoch 63/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 1.0678e-05\n",
      "Epoch 64/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 6.0037e-06 - val_loss: 3.3365e-06\n",
      "Epoch 65/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 1.7704e-06 - val_loss: 7.8635e-07\n",
      "Epoch 66/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 5.3884e-07 - val_loss: 2.8764e-07\n",
      "Epoch 67/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 2.7949e-06 - val_loss: 4.1677e-07\n",
      "Epoch 68/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 1.3817 - val_loss: 5.2060.6981\n",
      "Epoch 69/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.4155 - val_loss: 3.7202e-05\n",
      "Epoch 70/100\n",
      "279/279 [==============================] - 0s 996us/step - loss: 9.0263e-06 - val_loss: 1.1862e-07\n",
      "Epoch 71/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 3.5007e-05 - val_loss: 0.0031\n",
      "Epoch 72/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 15.0458 - val_loss: 2.0397e-04\n",
      "Epoch 73/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 1.5868e-05 - val_loss: 5.0774e-06\n",
      "Epoch 74/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 2.2499e-06 - val_loss: 1.2708e-06\n",
      "Epoch 75/100\n",
      "279/279 [==============================] - 0s 963us/step - loss: 4.0894e-06 - val_loss: 9.1008e-05\n",
      "Epoch 76/100\n",
      "279/279 [==============================] - 0s 944us/step - loss: 2.6060e-05 - val_loss: 1.3848e-05\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 0s 1ms/step - loss: 0.2537 - val_loss: 2.9128e-04\n",
      "Epoch 78/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0533\n",
      "Epoch 79/100\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 1.7681 - val_loss: 2.3410e-04\n",
      "Epoch 80/100\n",
      "279/279 [==============================] - 0s 916us/step - loss: 0.0081 - val_loss: 0.0156\n",
      "Epoch 81/100\n",
      "279/279 [==============================] - 0s 942us/step - loss: 1.1663 - val_loss: 0.7587\n",
      "Epoch 82/100\n",
      "279/279 [==============================] - 0s 985us/step - loss: 0.2044 - val_loss: 0.0084\n",
      "Epoch 83/100\n",
      "279/279 [==============================] - 0s 964us/step - loss: 1.9112 - val_loss: 3.7248\n",
      "Epoch 84/100\n",
      "279/279 [==============================] - 0s 949us/step - loss: 0.7408 - val_loss: 5.2628e-04\n",
      "Epoch 85/100\n",
      "279/279 [==============================] - 0s 959us/step - loss: 4.4140 - val_loss: 0.0041\n",
      "Epoch 86/100\n",
      "279/279 [==============================] - 0s 941us/step - loss: 0.0104 - val_loss: 2.1995e-06\n",
      "Epoch 87/100\n",
      "279/279 [==============================] - 0s 967us/step - loss: 3.6696e-06 - val_loss: 1.9961e-05\n",
      "Epoch 88/100\n",
      "279/279 [==============================] - 0s 938us/step - loss: 0.0818 - val_loss: 4.9817\n",
      "Epoch 89/100\n",
      "279/279 [==============================] - 0s 950us/step - loss: 1.2456 - val_loss: 66.9223\n",
      "Epoch 90/100\n",
      "279/279 [==============================] - 0s 990us/step - loss: 2.9309 - val_loss: 0.0158\n",
      "Epoch 91/100\n",
      "279/279 [==============================] - 0s 942us/step - loss: 0.0049 - val_loss: 3.1383e-04\n",
      "Epoch 92/100\n",
      "279/279 [==============================] - 0s 951us/step - loss: 8.5292e-05 - val_loss: 3.2702e-07\n",
      "Epoch 93/100\n",
      "279/279 [==============================] - 0s 931us/step - loss: 2.3812 - val_loss: 0.0148\n",
      "Epoch 94/100\n",
      "279/279 [==============================] - 0s 946us/step - loss: 0.0098 - val_loss: 0.0026\n",
      "Epoch 95/100\n",
      "279/279 [==============================] - 0s 941us/step - loss: 0.0044 - val_loss: 0.0372\n",
      "Epoch 96/100\n",
      "279/279 [==============================] - 0s 968us/step - loss: 5.5824 - val_loss: 3.2185e-06\n",
      "Epoch 97/100\n",
      "279/279 [==============================] - 0s 960us/step - loss: 1.2311e-06 - val_loss: 3.2704e-07\n",
      "Epoch 98/100\n",
      "279/279 [==============================] - 0s 944us/step - loss: 0.0159 - val_loss: 0.0391\n",
      "Epoch 99/100\n",
      "279/279 [==============================] - 0s 960us/step - loss: 0.2739 - val_loss: 0.9761\n",
      "Epoch 100/100\n",
      "279/279 [==============================] - 0s 972us/step - loss: 1.2958 - val_loss: 1.8169\n",
      "Computational time: 27.935098886489868 seconds\n",
      "\n",
      "Classification report for Autoencoder with K-Nearest Neighbors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       859\n",
      "           1       1.00      1.00      1.00      1366\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Autoencoder with under sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Balance the dataset using undersampling with the RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X, y = rus.fit_resample(X, y)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "autoencoder.add(Dense(units=32, activation='relu'))\n",
    "autoencoder.add(Dense(units=64, activation='relu'))\n",
    "autoencoder.add(Dense(units=X_train.shape[1]))\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder model\n",
    "autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_test, X_test))\n",
    "\n",
    "# Use the autoencoder to encode the training and testing data\n",
    "X_train_encoded = autoencoder.predict(X_train)\n",
    "X_test_encoded = autoencoder.predict(X_test)\n",
    "\n",
    "# Train the K-Nearest Neighbors model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predict the test set using K-Nearest Neighbors\n",
    "y_pred_knn = knn.predict(X_test_encoded)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for K-Nearest Neighbors\n",
    "cr_knn = classification_report(y_test, y_pred_knn)\n",
    "print(\"\\nClassification report for Autoencoder with K-Nearest Neighbors:\\n\", cr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01cec57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doneya\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.3564178943634033 seconds\n",
      "\n",
      "Classification report for Isolation Forest Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.78      0.46       859\n",
      "           1       0.00      0.00      0.00      1366\n",
      "\n",
      "    accuracy                           0.30      2225\n",
      "   macro avg       0.16      0.39      0.23      2225\n",
      "weighted avg       0.13      0.30      0.18      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Isolation Forest \n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Train the Isolation Forest Model\n",
    "isolation_forest = IsolationForest(contamination=0.1)\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "# Predict the test set using Isolation Forest Model\n",
    "y_pred_isolation_forest = isolation_forest.predict(X_test)\n",
    "y_pred_isolation_forest[y_pred_isolation_forest == 1] = 0\n",
    "y_pred_isolation_forest[y_pred_isolation_forest == -1] = 1\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for Isolation Forest Model\n",
    "cr_isolation_forest = classification_report(y_test, y_pred_isolation_forest)\n",
    "print(\"\\nClassification report for Isolation Forest Model:\\n\", cr_isolation_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36bfa17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doneya\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.39318370819091797 seconds\n",
      "\n",
      "Classification report for Isolation Forest Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.80      0.58      1374\n",
      "           1       0.00      0.00      0.00      1318\n",
      "\n",
      "    accuracy                           0.41      2692\n",
      "   macro avg       0.23      0.40      0.29      2692\n",
      "weighted avg       0.23      0.41      0.29      2692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Isolation Forest with oversampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Train the Isolation Forest Model\n",
    "isolation_forest = IsolationForest(contamination=0.1)\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "# Predict the test set using Isolation Forest Model\n",
    "y_pred_isolation_forest = isolation_forest.predict(X_test)\n",
    "y_pred_isolation_forest[y_pred_isolation_forest == 1] = 0\n",
    "y_pred_isolation_forest[y_pred_isolation_forest == -1] = 1\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for Isolation Forest Model\n",
    "cr_isolation_forest = classification_report(y_test, y_pred_isolation_forest)\n",
    "print(\"\\nClassification report for Isolation Forest Model:\\n\", cr_isolation_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8138253f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.31875085830688477 seconds\n",
      "\n",
      "Classification report for Isolation Forest Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.81      0.58       882\n",
      "           1       0.00      0.00      0.00       876\n",
      "\n",
      "    accuracy                           0.40      1758\n",
      "   macro avg       0.22      0.40      0.29      1758\n",
      "weighted avg       0.22      0.40      0.29      1758\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doneya\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Isolation Forest with undersampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using undersampling with the RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X, y = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Train the Isolation Forest Model\n",
    "isolation_forest = IsolationForest(contamination=0.1)\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "# Predict the test set using Isolation Forest Model\n",
    "y_pred_isolation_forest = isolation_forest.predict(X_test)\n",
    "y_pred_isolation_forest[y_pred_isolation_forest == 1] = 0\n",
    "y_pred_isolation_forest[y_pred_isolation_forest == -1] = 1\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for Isolation Forest Model\n",
    "cr_isolation_forest = classification_report(y_test, y_pred_isolation_forest)\n",
    "print(\"\\nClassification report for Isolation Forest Model:\\n\", cr_isolation_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef9d14e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.6242213249206543 seconds\n",
      "\n",
      "Classification report for One-Class SVM Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92       896\n",
      "           1       0.91      1.00      0.95      1329\n",
      "\n",
      "    accuracy                           0.94      2225\n",
      "   macro avg       0.95      0.92      0.94      2225\n",
      "weighted avg       0.94      0.94      0.94      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#One-Class SVM\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Train the One-Class SVM Model\n",
    "one_class_svm = OneClassSVM(nu=0.1)\n",
    "one_class_svm.fit(X_train)\n",
    "\n",
    "# Predict the test set using One-Class SVM Model\n",
    "y_pred_one_class_svm = one_class_svm.predict(X_test)\n",
    "y_pred_one_class_svm[y_pred_one_class_svm == 1] = 0\n",
    "y_pred_one_class_svm[y_pred_one_class_svm == -1] = 1\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for One-Class SVM Model\n",
    "cr_one_class_svm = classification_report(y_test, y_pred_one_class_svm)\n",
    "print(\"\\nClassification report for One-Class SVM Model:\\n\", cr_one_class_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4e40498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.9463891983032227 seconds\n",
      "\n",
      "Classification report for One-Class SVM Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1332\n",
      "           1       0.91      1.00      0.95      1360\n",
      "\n",
      "    accuracy                           0.95      2692\n",
      "   macro avg       0.96      0.95      0.95      2692\n",
      "weighted avg       0.96      0.95      0.95      2692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#One-Class SVM with over sampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import OneClassSVM\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Train the One-Class SVM Model\n",
    "one_class_svm = OneClassSVM(nu=0.1)\n",
    "one_class_svm.fit(X_train)\n",
    "\n",
    "# Predict the test set using One-Class SVM Model\n",
    "y_pred_one_class_svm = one_class_svm.predict(X_test)\n",
    "y_pred_one_class_svm[y_pred_one_class_svm == 1] = 0\n",
    "y_pred_one_class_svm[y_pred_one_class_svm == -1] = 1\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for One-Class SVM Model\n",
    "cr_one_class_svm = classification_report(y_test, y_pred_one_class_svm)\n",
    "print(\"\\nClassification report for One-Class SVM Model:\\n\", cr_one_class_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f981b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.42424821853637695 seconds\n",
      "\n",
      "Classification report for One-Class SVM Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.95      0.66       911\n",
      "           1       0.00      0.00      0.00       847\n",
      "\n",
      "    accuracy                           0.49      1758\n",
      "   macro avg       0.25      0.47      0.33      1758\n",
      "weighted avg       0.26      0.49      0.34      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#One-Class SVM with undersampling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import OneClassSVM\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using undersampling with the RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X, y = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Train the One-Class SVM Model\n",
    "one_class_svm = OneClassSVM(nu=0.1)\n",
    "one_class_svm.fit(X_train)\n",
    "\n",
    "# Predict the test set using One-Class SVM Model\n",
    "y_pred_one_class_svm = one_class_svm.predict(X_test)\n",
    "y_pred_one_class_svm[y_pred_one_class_svm == 1] = 0\n",
    "y_pred_one_class_svm[y_pred_one_class_svm == -1] = 1\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for One-Class SVM Model\n",
    "cr_one_class_svm = classification_report(y_test, y_pred_one_class_svm)\n",
    "print(\"\\nClassification report for One-Class SVM Model:\\n\", cr_one_class_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "390f7d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.07210636138916016 seconds\n",
      "\n",
      "Classification report for Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       865\n",
      "           1       1.00      1.00      1.00      1360\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set using Logistic Regression\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for Logistic Regression\n",
    "cr_log_reg = classification_report(y_test, y_pred_log_reg, zero_division='warn')\n",
    "\n",
    "print(\"\\nClassification report for Logistic Regression:\\n\", cr_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a210072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "279/279 [==============================] - 1s 1ms/step - loss: 0.1809 - accuracy: 0.9920 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "279/279 [==============================] - 0s 957us/step - loss: 0.0069 - accuracy: 0.9999 - val_loss: 4.5865e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "279/279 [==============================] - 0s 935us/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 1.1266e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "279/279 [==============================] - 0s 973us/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 3.9866e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "279/279 [==============================] - 0s 913us/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 1.5313e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "279/279 [==============================] - 0s 900us/step - loss: 9.2894e-04 - accuracy: 0.9997 - val_loss: 6.7683e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "279/279 [==============================] - 0s 917us/step - loss: 6.1228e-04 - accuracy: 0.9999 - val_loss: 3.1588e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "279/279 [==============================] - 0s 912us/step - loss: 5.1057e-04 - accuracy: 0.9999 - val_loss: 1.6018e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "279/279 [==============================] - 0s 922us/step - loss: 3.0713e-04 - accuracy: 1.0000 - val_loss: 8.1505e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "279/279 [==============================] - 0s 909us/step - loss: 3.5418e-04 - accuracy: 0.9999 - val_loss: 4.2001e-07 - val_accuracy: 1.0000\n",
      "Test Accuracy: 1.0\n",
      "Computational time: 3.2405669689178467 seconds\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       887\n",
      "           1       1.00      1.00      1.00      1338\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CNN with compuation time\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for the CNN\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1, 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1, 1))\n",
    "\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 1), activation='relu', input_shape=(X_train.shape[1], 1, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "#Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Convert the predictions back to binary labels\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "\n",
    "#Print the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print('Classification report:')\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79692eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "337/337 [==============================] - 1s 1ms/step - loss: 0.1601 - accuracy: 0.9852 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "337/337 [==============================] - 0s 924us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.6649e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "337/337 [==============================] - 0s 918us/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 6.5765e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "337/337 [==============================] - 0s 927us/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 2.2405e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "337/337 [==============================] - 0s 939us/step - loss: 7.5649e-04 - accuracy: 0.9999 - val_loss: 9.2134e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "337/337 [==============================] - 0s 940us/step - loss: 5.6256e-04 - accuracy: 0.9999 - val_loss: 4.3578e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "337/337 [==============================] - 0s 922us/step - loss: 3.9505e-04 - accuracy: 1.0000 - val_loss: 2.0012e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "337/337 [==============================] - 0s 959us/step - loss: 3.3343e-04 - accuracy: 1.0000 - val_loss: 9.8226e-07 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "337/337 [==============================] - 0s 891us/step - loss: 2.2980e-04 - accuracy: 1.0000 - val_loss: 5.2994e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "337/337 [==============================] - 0s 940us/step - loss: 2.0877e-04 - accuracy: 1.0000 - val_loss: 2.8580e-07 - val_accuracy: 1.0000\n",
      "Test Accuracy: 1.0\n",
      "Computational time: 3.7756450176239014 seconds\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1342\n",
      "           1       1.00      1.00      1.00      1350\n",
      "\n",
      "    accuracy                           1.00      2692\n",
      "   macro avg       1.00      1.00      1.00      2692\n",
      "weighted avg       1.00      1.00      1.00      2692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CNN with oversampling\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for the CNN\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1, 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1, 1))\n",
    "\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 1), activation='relu', input_shape=(X_train.shape[1], 1, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "#Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Convert the predictions back to binary labels\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "\n",
    "#Print the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print('Classification report:')\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12443414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "220/220 [==============================] - 1s 1ms/step - loss: 0.2119 - accuracy: 0.9876 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.6870e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.1798e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.1162e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 986us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.3327e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 9.9639e-04 - accuracy: 1.0000 - val_loss: 1.1727e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.8058e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 8.1099e-04 - accuracy: 1.0000 - val_loss: 4.4378e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 6.5778e-04 - accuracy: 1.0000 - val_loss: 2.7388e-06 - val_accuracy: 1.0000\n",
      "Test Accuracy: 1.0\n",
      "Computational time: 2.903202772140503 seconds\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       909\n",
      "           1       1.00      1.00      1.00       849\n",
      "\n",
      "    accuracy                           1.00      1758\n",
      "   macro avg       1.00      1.00      1.00      1758\n",
      "weighted avg       1.00      1.00      1.00      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CNN with undersampling\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Balance the dataset using undersampling with the RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X, y = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for the CNN\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1, 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1, 1))\n",
    "\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 1), activation='relu', input_shape=(X_train.shape[1], 1, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "#Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Convert the predictions back to binary labels\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "\n",
    "#Print the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print('Classification report:')\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68441852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.05008292198181152 seconds\n",
      "\n",
      "Classification report for KMeans:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4395\n",
      "           1       1.00      1.00      1.00      6728\n",
      "\n",
      "    accuracy                           1.00     11123\n",
      "   macro avg       1.00      1.00      1.00     11123\n",
      "weighted avg       1.00      1.00      1.00     11123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Clustering with KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "#Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "#Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "#Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df['label']\n",
    "\n",
    "#Train the KMeans model\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "\n",
    "#Predict the target variable using KMeans\n",
    "y_pred_kmeans = kmeans.predict(X)\n",
    "\n",
    "#Calculate computational time\n",
    "end_time = time.time()\n",
    "computational_time = end_time - start_time\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "#Calculate the precision, recall, and f1-score for KMeans\n",
    "cr_kmeans = classification_report(y, y_pred_kmeans)\n",
    "print(\"\\nClassification report for KMeans:\\n\", cr_kmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c790f7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "279/279 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9756 - val_loss: 8.5078e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "279/279 [==============================] - 0s 2ms/step - loss: 5.5882e-04 - accuracy: 1.0000 - val_loss: 2.8233e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "279/279 [==============================] - 0s 2ms/step - loss: 2.3670e-04 - accuracy: 1.0000 - val_loss: 1.4464e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "279/279 [==============================] - 0s 2ms/step - loss: 1.3386e-04 - accuracy: 1.0000 - val_loss: 8.8796e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "279/279 [==============================] - 0s 2ms/step - loss: 8.7192e-05 - accuracy: 1.0000 - val_loss: 5.9746e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "279/279 [==============================] - 0s 2ms/step - loss: 6.1140e-05 - accuracy: 1.0000 - val_loss: 4.2488e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "279/279 [==============================] - 0s 2ms/step - loss: 4.4407e-05 - accuracy: 1.0000 - val_loss: 3.1584e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "279/279 [==============================] - 0s 2ms/step - loss: 3.3690e-05 - accuracy: 1.0000 - val_loss: 2.4251e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "279/279 [==============================] - 0s 2ms/step - loss: 2.6753e-05 - accuracy: 1.0000 - val_loss: 1.9007e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "279/279 [==============================] - 0s 2ms/step - loss: 2.1230e-05 - accuracy: 1.0000 - val_loss: 1.5196e-05 - val_accuracy: 1.0000\n",
      "Computational time: 5.733065843582153 seconds\n",
      "\n",
      "Classification report for Recurrent Neural Network:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       888\n",
      "           1       1.00      1.00      1.00      1337\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Reshape the input data for the RNN\n",
    "X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "#Initialize the RNN model\n",
    "model = Sequential()\n",
    "\n",
    "#Add a simple RNN layer with 128 hidden units\n",
    "model.add(SimpleRNN(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "\n",
    "#Add a dropout layer to prevent overfitting\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Add a dense layer for prediction\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compile the RNN model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Train the RNN model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#Predict the test set using the RNN model\n",
    "y_pred_rnn = model.predict(X_test)\n",
    "y_pred_rnn = np.round(y_pred_rnn).astype(int).flatten()\n",
    "\n",
    "#Calculate computation time\n",
    "end_time = time.time()\n",
    "\n",
    "computational_time = end_time - start_time\n",
    "\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "#Calculate the precision, recall, and f1-score for the RNN model\n",
    "cr_rnn = classification_report(y_test, y_pred_rnn, zero_division=1)\n",
    "print(\"\\nClassification report for Recurrent Neural Network:\\n\", cr_rnn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74300666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 0.1590576171875 seconds\n",
      "\n",
      "Classification report for Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       877\n",
      "           1       1.00      1.00      1.00      1348\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the Gradient Boosting Classifier model\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set using Gradient Boosting Classifier\n",
    "y_pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Calculate computation time\n",
    "end_time = time.time()\n",
    "\n",
    "computational_time = end_time - start_time\n",
    "\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for Gradient Boosting Classifier\n",
    "cr_gbc = classification_report(y_test, y_pred_gbc)\n",
    "print(\"\\nClassification report for Gradient Boosting Classifier:\\n\", cr_gbc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15fa4af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational time: 1.9675331115722656 seconds\n",
      "\n",
      "Classification report for Deep Belief Networks:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       870\n",
      "           1       0.61      1.00      0.76      1355\n",
      "\n",
      "    accuracy                           0.61      2225\n",
      "   macro avg       0.80      0.50      0.38      2225\n",
      "weighted avg       0.76      0.61      0.46      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Deep Belief Networks (DBN) \n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data from the csv file into a pandas DataFrame\n",
    "goose_df = pd.read_csv('goose_data_new-2.csv')\n",
    "\n",
    "# Encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "goose_df['source'] = label_encoder.fit_transform(goose_df['source'])\n",
    "goose_df['destination'] = label_encoder.fit_transform(goose_df['destination'])\n",
    "goose_df['gooseid'] = label_encoder.fit_transform(goose_df['gooseid'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "goose_df['stNum'] = imputer.fit_transform(goose_df[['stNum']])\n",
    "\n",
    "# Create new features\n",
    "goose_df['goose_interaction'] = goose_df['stNum'] * goose_df['gooseid']\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = goose_df.drop(columns=[\"time\", \"sqNum\", \"gooseboolean\", \"goosebitstring\", \"label\"])\n",
    "y = goose_df[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create the DBN model\n",
    "dbn = Pipeline(steps=[('rbm', BernoulliRBM(n_components=50, learning_rate=0.01, n_iter=20, random_state=0)),\n",
    "                      ('logistic', LogisticRegression(C=1000.0, max_iter=10000))])\n",
    "\n",
    "# Train the DBN model\n",
    "dbn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set using DBN\n",
    "y_pred_dbn = dbn.predict(X_test)\n",
    "\n",
    "#Calculate computation time\n",
    "end_time = time.time()\n",
    "\n",
    "computational_time = end_time - start_time\n",
    "\n",
    "print(\"Computational time:\", computational_time, \"seconds\")\n",
    "\n",
    "# Calculate the precision, recall, and f1-score for DBN\n",
    "cr_dbn = classification_report(y_test, y_pred_dbn, zero_division=1)\n",
    "print(\"\\nClassification report for Deep Belief Networks:\\n\", cr_dbn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb9364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
